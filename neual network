import numpy as np
def sigmoid(x):
    s = 1/(1+np.exp(-x))
    return s
def init_W():
    
    n = input('input dim:')
    M = input('output dim:')
    np.random.seed(3)
    W=np.random.randn(int(M),int(n))*.01
    #b = np.zeros((int(M),1))*.01
    return W,int(M)
def init_b(M):
    b = np.zeros((int(M),1))*.01
    return b

def nueral_network(X,Y,I,N,learningrate):
    m = X.shape[1]
    #np.random.seed(2)
    for x in range(1, N+1):
        globals()['W%s' % x],M =init_W()
        globals()['b%s' % x] = init_b(M)
    for i in range(0,I):
### Foward popagation
        for i in range(1,N+1):
            if i ==1:
                globals()['Z%s' % int(i)]=np.dot(globals()['W%s' % int(i)],X)+globals()['b%s' % int(i)]
                globals()['A%s' % int(i)]=np.tanh(globals()['Z%s' % int(i)])
            if i == N:
                globals()['Z%s' % int(i)]=np.dot(globals()['W%s' % int(i)],globals()['A%s' % int(i-1)])+globals()['b%s' % int(i)]
                globals()['A%s' % int(i)]=sigmoid(globals()['Z%s' % int(i)])                
            if (i!=1) and (i!=N):
                globals()['Z%s' % int(i)]=np.dot(globals()['W%s' % int(i)],globals()['A%s' % int(i-1)])+globals()['b%s' % int(i)]
                globals()['A%s' % int(i)]=np.tanh(globals()['Z%s' % int(i)])
### Backward popagation
        for i in range(-N,0):
            if i == -int(N):
                globals()['dz%s' % -i]=globals()['A%s' % -i] -Y
                globals()['dW%s' % -i]= (1/m)*(np.dot(globals()['dz%s' % -i],globals()['A%s' % -(i+1)].T))
                globals()['db%s' % -i]= (1/m)*(np.sum(globals()['dz%s' % -i], axis=1, keepdims=True))
            if i==-1:
                globals()['dz%s' % -i] = (np.dot(globals()['W%s' % -(i-1)].T,globals()['dz%s' % -(i-1)]))*(1-np.power(globals()['A%s' % -i],2))
                globals()['dW%s' % -i]= (1/m)*(np.dot(globals()['dz%s' % -i],X.T))
                globals()['db%s' % -i]= (1/m)*(np.sum(globals()['dz%s' % -i], axis=1, keepdims=True))        
            if (i!=-1) and (i!=-N):
                globals()['dz%s' % -i] = (np.dot(globals()['W%s' % -(i-1)].T,globals()['dz%s' % -(i-1)]))*(1-np.power(globals()['A%s' % -i],2))
                globals()['dW%s' % -i]= (1/m)*(np.dot(globals()['dz%s' % -i],globals()['A%s' % -(i+1)].T))
                globals()['db%s' % -i]= (1/m)*(np.sum(globals()['dz%s' % -i], axis=1, keepdims=True))      
### weight updates
        for i in range(1,N+1):
                globals()['W%s' % i]=globals()['W%s' % i]-learningrate*globals()['dW%s' % i]
                globals()['b%s' % i]=globals()['b%s' % i]-learningrate*globals()['db%s' % i]

    Cost=(-1/m)*np.sum((Y*np.log(globals()['A%s' % N]))+((1-Y)*np.log(1-globals()['A%s' % N])))
    print(Cost)
    return globals()['A%s' % N]

yp=nueral_network(X,Y,30000,3
                  ,1.2)

def load_planar_dataset():
    np.random.seed(1)
    m = 400 # number of examples
    N = int(m/2) # number of points per class
    D = 2 # dimensionality
    X = np.zeros((m,D)) # data matrix where each row is a single example
    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)
    a = 4 # maximum ray of the flower

    for j in range(2):
        ix = range(N*j,N*(j+1))
        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta
        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius
        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
        Y[ix] = j
        
    X = X.T
    Y = Y.T

    return X, Y
X,Y = load_planar_dataset()
